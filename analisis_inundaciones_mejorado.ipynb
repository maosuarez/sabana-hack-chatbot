{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Datos y Modelado Predictivo para Eventos de Inundación\n",
    "\n",
    "Este notebook presenta un análisis exhaustivo y modelado predictivo realizado sobre un dataset de variables hidrológicas y meteorológicas relacionadas con eventos de inundación.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Realizar un análisis exploratorio de datos (EDA)\n",
    "2. Preparar y limpiar los datos\n",
    "3. Balancear las clases para mejorar el modelado\n",
    "4. Construir y evaluar modelos predictivos\n",
    "5. Validar los modelos y analizar su confiabilidad\n",
    "\n",
    "## Descripción del Dataset\n",
    "\n",
    "El dataset \"datos_final.csv\" contiene registros horarios con las siguientes variables:\n",
    "- `hour_updated`: Fecha y hora de la medición\n",
    "- `p01m`: Medida de precipitación (mm)\n",
    "- `cfs`: Caudal (pies cúbicos por segundo)\n",
    "- `height`: Altura del agua (m)\n",
    "- `flood_event`: Variable objetivo, indica si ocurrió una inundación (1) o no (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importación de Bibliotecas\n",
    "\n",
    "Primero, importamos todas las bibliotecas necesarias para el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar el estilo de las visualizaciones\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('deep')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carga y Exploración Inicial de Datos\n",
    "\n",
    "Cargamos el dataset y realizamos una exploración inicial para entender su estructura y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Cargar los datos\n",
    "print(\"1. CARGANDO DATOS\")\n",
    "data = pd.read_csv('datos_final.csv')\n",
    "print(f\"Dimensiones del dataset: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Exploración inicial de los datos\n",
    "print(\"\\n2. EXPLORACIÓN INICIAL\")\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Información del dataset\n",
    "print(\"\\nInformación del dataset:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Ahora realizaremos un análisis exploratorio más profundo para entender mejor nuestros datos y descubrir patrones e insights relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Verificación de Valores Nulos\n",
    "\n",
    "Verificamos si hay valores nulos en el dataset que necesiten ser tratados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verificar valores nulos\n",
    "print(\"\\n3. VERIFICANDO VALORES NULOS\")\n",
    "nulos = data.isnull().sum()\n",
    "print(nulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Exploración de la Variable Objetivo\n",
    "\n",
    "Analizamos la distribución de la variable objetivo (`flood_event`) para entender el balance entre las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Explorar la variable objetivo\n",
    "print(\"\\n4. EXPLORANDO LA VARIABLE OBJETIVO (flood_event)\")\n",
    "print(data['flood_event'].value_counts())\n",
    "print(f\"Proporción de eventos de inundación: {data['flood_event'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Visualizar la distribución de clases\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.countplot(x='flood_event', data=data)\n",
    "plt.title('Distribución de la Variable Objetivo (flood_event)', fontsize=16)\n",
    "plt.xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=14)\n",
    "plt.ylabel('Cantidad de Registros', fontsize=14)\n",
    "\n",
    "# Añadir etiquetas con la cantidad y porcentaje\n",
    "total = len(data)\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width()/2.,\n",
    "            height + 0.1,\n",
    "            f'{height}\\n({height/total:.1%})',\n",
    "            ha=\"center\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución muestra un claro desbalance entre las clases, con aproximadamente un 3% de eventos de inundación. Este desbalance es típico en fenómenos extremos y requerirá técnicas especiales para el modelado.\n",
    "\n",
    "Este tipo de desbalance representa un desafío para los modelos de machine learning porque:\n",
    "1. Pueden estar sesgados hacia la predicción de la clase mayoritaria\n",
    "2. Las métricas tradicionales como la precisión (accuracy) pueden ser engañosas\n",
    "3. El modelo puede no aprender adecuadamente los patrones que conducen a inundaciones\n",
    "\n",
    "Por estas razones, más adelante aplicaremos técnicas de balanceo como SMOTE y Random Undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Análisis Temporal\n",
    "\n",
    "Analizamos la distribución temporal de los eventos para identificar patrones estacionales o tendencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Análisis temporal\n",
    "print(\"\\n5. ANÁLISIS TEMPORAL\")\n",
    "# Convertir la columna de hora a datetime\n",
    "data['hour_updated'] = pd.to_datetime(data['hour_updated'])\n",
    "data['year'] = data['hour_updated'].dt.year\n",
    "data['month'] = data['hour_updated'].dt.month\n",
    "data['day'] = data['hour_updated'].dt.day\n",
    "data['hour'] = data['hour_updated'].dt.hour\n",
    "\n",
    "# Analizar eventos de inundación por año y mes\n",
    "eventos_por_anio = data.groupby('year')['flood_event'].sum().reset_index()\n",
    "eventos_por_mes = data.groupby(['year', 'month'])['flood_event'].sum().reset_index()\n",
    "\n",
    "# Visualizar eventos por año\n",
    "plt.figure(figsize=(14, 7))\n",
    "ax = sns.barplot(x='year', y='flood_event', data=eventos_por_anio)\n",
    "plt.title('Eventos de Inundación por Año', fontsize=16)\n",
    "plt.xlabel('Año', fontsize=14)\n",
    "plt.ylabel('Número de Eventos', fontsize=14)\n",
    "\n",
    "# Añadir etiquetas con la cantidad\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'bottom', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Visualizar eventos por mes (heatmap)\n",
    "eventos_heatmap = eventos_por_mes.pivot(index='year', columns='month', values='flood_event').fillna(0)\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.heatmap(eventos_heatmap, annot=True, fmt='g', cmap='YlOrRd', linewidths=.5)\n",
    "plt.title('Eventos de Inundación por Mes y Año', fontsize=16)\n",
    "plt.xlabel('Mes', fontsize=14)\n",
    "plt.ylabel('Año', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis temporal nos permite identificar patrones estacionales y tendencias a lo largo del tiempo. Podemos observar si ciertos meses o años tienen una mayor incidencia de eventos de inundación. Esta información es valiosa para entender la naturaleza cíclica o estacional del fenómeno y puede ser útil para construir características temporales que mejoren nuestros modelos predictivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Análisis de Correlaciones\n",
    "\n",
    "Analizamos las correlaciones entre las variables numéricas para entender sus relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Análisis de correlaciones\n",
    "print(\"\\n6. ANÁLISIS DE CORRELACIONES\")\n",
    "correlaciones = data[['p01m', 'cfs', 'height', 'flood_event']].corr()\n",
    "print(correlaciones)\n",
    "\n",
    "# Visualizar matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlaciones, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1, square=True)\n",
    "plt.title('Matriz de Correlación', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de la Matriz de Correlación\n",
    "\n",
    "La matriz de correlación muestra el coeficiente de correlación de Pearson entre cada par de variables. Este coeficiente varía entre -1 y 1, donde:\n",
    "\n",
    "- **1**: Correlación positiva perfecta (cuando una variable aumenta, la otra aumenta proporcionalmente)\n",
    "- **0**: No hay correlación lineal\n",
    "- **-1**: Correlación negativa perfecta (cuando una variable aumenta, la otra disminuye proporcionalmente)\n",
    "\n",
    "En la visualización, los colores ayudan a interpretar los valores:\n",
    "- **Rojo intenso**: Correlación positiva fuerte\n",
    "- **Azul intenso**: Correlación negativa fuerte\n",
    "- **Colores claros**: Correlación débil o nula\n",
    "\n",
    "#### Observaciones clave:\n",
    "\n",
    "1. **p01m vs cfs**: Correlación cercana a 1, lo que indica una relación muy fuerte entre precipitación y caudal. Esto es lógico ya que un aumento en las precipitaciones suele provocar un aumento en el caudal de agua.\n",
    "\n",
    "2. **p01m/cfs vs flood_event**: Correlación moderada positiva (aproximadamente 0.52), indicando que estas variables son buenos predictores de eventos de inundación. A mayor precipitación y caudal, mayor probabilidad de inundación.\n",
    "\n",
    "3. **height vs otras variables**: Correlación muy baja (cerca de 0), lo que sugiere que la altura del agua medida en este contexto no tiene una relación lineal fuerte con las otras variables. Esto puede parecer contraintuitivo, pero podría explicarse si:\n",
    "   - La altura se mide en un punto que no refleja bien los cambios en el sistema hidrológico general\n",
    "   - Hay un retraso significativo entre los cambios en precipitación/caudal y los cambios en altura\n",
    "   - La relación es no lineal (el coeficiente de Pearson solo captura relaciones lineales)\n",
    "\n",
    "#### Implicaciones para el modelado:\n",
    "\n",
    "- La alta correlación entre p01m y cfs sugiere **multicolinealidad**, lo que podría afectar a algunos tipos de modelos. En modelos como regresión lineal, podría ser recomendable eliminar una de estas variables, pero en modelos de árbol como Random Forest, esto no suele ser un problema.\n",
    "\n",
    "- Las correlaciones moderadas con la variable objetivo sugieren que p01m y cfs serán características importantes para nuestro modelo predictivo.\n",
    "\n",
    "- La baja correlación de height sugiere que podríamos necesitar transformar esta variable o crear variables derivadas (como cambios en la altura) para capturar mejor su relación con los eventos de inundación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Distribución de Variables Numéricas\n",
    "\n",
    "Visualizamos la distribución de las variables predictoras para entender mejor su comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Distribución de variables numéricas\n",
    "print(\"\\n7. DISTRIBUCIÓN DE VARIABLES NUMÉRICAS\")\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 20))\n",
    "\n",
    "sns.histplot(data=data, x='p01m', kde=True, ax=axes[0])\n",
    "axes[0].set_title('Distribución de p01m (Precipitación)', fontsize=16)\n",
    "axes[0].set_xlabel('p01m (mm)', fontsize=14)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=14)\n",
    "\n",
    "sns.histplot(data=data, x='cfs', kde=True, ax=axes[1])\n",
    "axes[1].set_title('Distribución de cfs (Caudal)', fontsize=16)\n",
    "axes[1].set_xlabel('cfs (pies cúbicos por segundo)', fontsize=14)\n",
    "axes[1].set_ylabel('Frecuencia', fontsize=14)\n",
    "\n",
    "sns.histplot(data=data, x='height', kde=True, ax=axes[2])\n",
    "axes[2].set_title('Distribución de height (Altura)', fontsize=16)\n",
    "axes[2].set_xlabel('height (m)', fontsize=14)\n",
    "axes[2].set_ylabel('Frecuencia', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas distribuciones nos ayudan a entender cómo se comportan las variables predictoras. Podemos observar:\n",
    "\n",
    "- **p01m y cfs**: Distribuciones sesgadas a la derecha (asimetría positiva), con la mayoría de valores concentrados en el rango inferior y una cola larga hacia valores más altos. Esto es típico en variables como precipitación y caudal, donde la mayoría de las mediciones son bajas o moderadas, pero ocasionalmente se producen valores extremos.\n",
    "\n",
    "- **height**: Distribución multimodal (múltiples picos), lo que sugiere diferentes estados o niveles estables del cuerpo de agua en diferentes momentos. Esta complejidad podría explicar su baja correlación lineal con las otras variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Relación entre Variables Predictoras y Variable Objetivo\n",
    "\n",
    "Analizamos cómo se relacionan las variables predictoras con la variable objetivo mediante diagramas de caja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Relación entre variables predictoras y la variable objetivo\n",
    "print(\"\\n8. RELACIÓN ENTRE VARIABLES PREDICTORAS Y OBJETIVO\")\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 20))\n",
    "\n",
    "sns.boxplot(x='flood_event', y='p01m', data=data, ax=axes[0])\n",
    "axes[0].set_title('p01m vs flood_event', fontsize=16)\n",
    "axes[0].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=14)\n",
    "axes[0].set_ylabel('p01m (mm)', fontsize=14)\n",
    "\n",
    "sns.boxplot(x='flood_event', y='cfs', data=data, ax=axes[1])\n",
    "axes[1].set_title('cfs vs flood_event', fontsize=16)\n",
    "axes[1].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=14)\n",
    "axes[1].set_ylabel('cfs (pies cúbicos por segundo)', fontsize=14)\n",
    "\n",
    "sns.boxplot(x='flood_event', y='height', data=data, ax=axes[2])\n",
    "axes[2].set_title('height vs flood_event', fontsize=16)\n",
    "axes[2].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=14)\n",
    "axes[2].set_ylabel('height (m)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los diagramas de caja nos muestran cómo se distribuyen las variables predictoras en función de la variable objetivo. Esto nos ayuda a identificar si hay diferencias significativas entre los eventos de inundación y no inundación para cada variable predictora.\n",
    "\n",
    "Observaciones:\n",
    "- **p01m y cfs**: Muestran una clara diferencia entre eventos de inundación (1) y no inundación (0). Los eventos de inundación tienen valores mucho más altos, lo que confirma su poder predictivo.\n",
    "- **height**: La diferencia es menos pronunciada, lo que concuerda con su baja correlación con la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparación de los Datos\n",
    "\n",
    "En esta sección, preparamos los datos para el modelado, realizando ingeniería de características, división en conjuntos de entrenamiento, validación y prueba, escalado y balanceo de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preparación de los datos\n",
    "print(\"\\n9. PREPARACIÓN DE LOS DATOS\")\n",
    "\n",
    "# Extraer características de tiempo (características cíclicas)\n",
    "data['sin_hora'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "data['cos_hora'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "data['sin_mes'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "data['cos_mes'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "\n",
    "# Crear variables de rezago (lag) para capturar tendencias\n",
    "for i in range(1, 4):  # Crear 3 variables de rezago\n",
    "    data[f'p01m_lag_{i}'] = data['p01m'].shift(i)\n",
    "    data[f'cfs_lag_{i}'] = data['cfs'].shift(i)\n",
    "    data[f'height_lag_{i}'] = data['height'].shift(i)\n",
    "\n",
    "# Eliminar los registros con NaN debido a los rezagos\n",
    "data = data.dropna()\n",
    "\n",
    "# Características a utilizar en el modelo\n",
    "features = ['p01m', 'cfs', 'height', \n",
    "            'sin_hora', 'cos_hora', 'sin_mes', 'cos_mes',\n",
    "            'p01m_lag_1', 'p01m_lag_2', 'p01m_lag_3',\n",
    "            'cfs_lag_1', 'cfs_lag_2', 'cfs_lag_3',\n",
    "            'height_lag_1', 'height_lag_2', 'height_lag_3']\n",
    "\n",
    "X = data[features]\n",
    "y = data['flood_event']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 División de Datos en Train, Validation y Test\n",
    "\n",
    "Dividiremos nuestros datos en tres conjuntos:\n",
    "- **Train (60%)**: Para entrenar los modelos\n",
    "- **Validation (20%)**: Para ajustar hiperparámetros y evitar el sobreajuste\n",
    "- **Test (20%)**: Para la evaluación final del modelo\n",
    "\n",
    "Esta división es una práctica recomendada que nos permite evaluar de manera más robusta el rendimiento de nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Dividir datos en conjuntos de entrenamiento, validación y prueba\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp) \n",
    "# 0.25 * 0.8 = 0.2 del conjunto original\n",
    "\n",
    "# Escalado de características\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Mostrar la forma de los conjuntos de datos\n",
    "print(f\"Forma de X_train: {X_train.shape}\")\n",
    "print(f\"Forma de X_val: {X_val.shape}\")\n",
    "print(f\"Forma de X_test: {X_test.shape}\")\n",
    "print(f\"\\nDistribución de y_train: \\n{pd.Series(y_train).value_counts()}\")\n",
    "print(f\"\\nDistribución de y_val: \\n{pd.Series(y_val).value_counts()}\")\n",
    "print(f\"\\nDistribución de y_test: \\n{pd.Series(y_test).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Balanceo de Clases\n",
    "\n",
    "Aplicamos técnicas de balanceo para mejorar el rendimiento de los modelos con datos desbalanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Balanceo de clases\n",
    "print(\"\\n10. BALANCEO DE CLASES\")\n",
    "print(\"Antes del balanceo:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Aplicar SMOTE (sobremuestreo)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nDespués del balanceo con SMOTE:\")\n",
    "print(pd.Series(y_train_smote).value_counts())\n",
    "\n",
    "# También probaremos submuestreo\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"\\nDespués del balanceo con RandomUnderSampler:\")\n",
    "print(pd.Series(y_train_rus).value_counts())\n",
    "\n",
    "# Visualizar la distribución después del balanceo\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.countplot(x=y_train, ax=axes[0])\n",
    "axes[0].set_title('Distribución Original', fontsize=14)\n",
    "axes[0].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "sns.countplot(x=y_train_smote, ax=axes[1])\n",
    "axes[1].set_title('Después de SMOTE', fontsize=14)\n",
    "axes[1].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=12)\n",
    "axes[1].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "sns.countplot(x=y_train_rus, ax=axes[2])\n",
    "axes[2].set_title('Después de RandomUnderSampler', fontsize=14)\n",
    "axes[2].set_xlabel('Evento de Inundación (0=No, 1=Sí)', fontsize=12)\n",
    "axes[2].set_ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas de Balanceo Explicadas:\n",
    "\n",
    "1. **SMOTE (Synthetic Minority Over-sampling Technique)**:\n",
    "   - Genera ejemplos sintéticos de la clase minoritaria (eventos de inundación)\n",
    "   - Funciona creando nuevos ejemplos a lo largo de los segmentos de línea que unen puntos vecinos de la clase minoritaria\n",
    "   - Ventaja: Mantiene toda la información de la clase mayoritaria\n",
    "   - Desventaja: Puede crear ejemplos sintéticos en regiones no realistas del espacio de características\n",
    "\n",
    "2. **Random Undersampling (RUS)**:\n",
    "   - Reduce aleatoriamente la cantidad de ejemplos en la clase mayoritaria (no inundación)\n",
    "   - Ventaja: Método simple y rápido\n",
    "   - Desventaja: Puede descartar información valiosa de la clase mayoritaria\n",
    "\n",
    "Probaremos ambos enfoques para determinar cuál produce mejores resultados en nuestros modelos. El balanceo solo se aplica al conjunto de entrenamiento, mientras que los conjuntos de validación y prueba mantienen la distribución original para reflejar el escenario real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelado y Evaluación\n",
    "\n",
    "En esta sección, entrenamos y evaluamos diferentes modelos de clasificación utilizando distintas estrategias de balanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Función para evaluar y mostrar resultados\n",
    "def evaluar_modelo(nombre, modelo, X_train, y_train, X_val, y_val, X_test=None, y_test=None):\n",
    "    # Entrenar el modelo\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en conjunto de validación\n",
    "    y_val_pred = modelo.predict(X_val)\n",
    "    \n",
    "    # Calcular métricas en validación\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    val_prec = precision_score(y_val, y_val_pred)\n",
    "    val_rec = recall_score(y_val, y_val_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"\\n--- Resultados de {nombre} en Validación ---\")\n",
    "    print(f\"Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Precision: {val_prec:.4f}\")\n",
    "    print(f\"Recall: {val_rec:.4f}\")\n",
    "    print(f\"F1-Score: {val_f1:.4f}\")\n",
    "    \n",
    "    # Matriz de confusión para validación\n",
    "    cm_val = confusion_matrix(y_val, y_val_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', xticklabels=['No inundación', 'Inundación'], \n",
    "                yticklabels=['No inundación', 'Inundación'])\n",
    "    plt.ylabel('Real', fontsize=14)\n",
    "    plt.xlabel('Predicción', fontsize=14)\n",
    "    plt.title(f'Matriz de Confusión (Validación) - {nombre}', fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    # Probabilidades para curva ROC (validación)\n",
    "    y_val_proba = modelo.predict_proba(X_val)[:, 1]\n",
    "    val_fpr, val_tpr, _ = roc_curve(y_val, y_val_proba)\n",
    "    val_roc_auc = auc(val_fpr, val_tpr)\n",
    "    \n",
    "    # Curva Precision-Recall (validación)\n",
    "    val_precision, val_recall, _ = precision_recall_curve(y_val, y_val_proba)\n",
    "    val_pr_auc = auc(val_recall, val_precision)\n",
    "    \n",
    "    # Gráficas ROC y Precision-Recall\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "    \n",
    "    # ROC\n",
    "    axes[0].plot(val_fpr, val_tpr, label=f'Validación (AUC = {val_roc_auc:.4f})')\n",
    "    axes[0].plot([0, 1], [0, 1], 'k--')\n",
    "    axes[0].set_xlabel('Tasa de Falsos Positivos', fontsize=14)\n",
    "    axes[0].set_ylabel('Tasa de Verdaderos Positivos', fontsize=14)\n",
    "    axes[0].set_title(f'Curva ROC - {nombre}', fontsize=16)\n",
    "    axes[0].legend(loc='lower right', fontsize=12)\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Precision-Recall\n",
    "    axes[1].plot(val_recall, val_precision, label=f'Validación (AUC = {val_pr_auc:.4f})')\n",
    "    axes[1].set_xlabel('Recall', fontsize=14)\n",
    "    axes[1].set_ylabel('Precision', fontsize=14)\n",
    "    axes[1].set_title(f'Curva Precision-Recall - {nombre}', fontsize=16)\n",
    "    axes[1].legend(loc='lower left', fontsize=12)\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Si se proporcionan datos de prueba, evaluar en ellos también\n",
    "    if X_test is not None and y_test is not None:\n",
    "        y_test_pred = modelo.predict(X_test)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        test_prec = precision_score(y_test, y_test_pred)\n",
    "        test_rec = recall_score(y_test, y_test_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        \n",
    "        print(f\"\\n--- Resultados de {nombre} en Test ---\")\n",
    "        print(f\"Accuracy: {test_acc:.4f}\")\n",
    "        print(f\"Precision: {test_prec:.4f}\")\n",
    "        print(f\"Recall: {test_rec:.4f}\")\n",
    "        print(f\"F1-Score: {test_f1:.4f}\")\n",
    "        \n",
    "        return modelo, val_acc, val_prec, val_rec, val_f1, val_roc_auc, test_acc, test_prec, test_rec, test_f1\n",
    "    \n",
    "    return modelo, val_acc, val_prec, val_rec, val_f1, val_roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Entrenamiento y evaluación de modelos\n",
    "print(\"\\n11. ENTRENAMIENTO Y EVALUACIÓN DE MODELOS\")\n",
    "\n",
    "# 11.1 Modelo de Regresión Logística\n",
    "print(\"\\n11.1 REGRESIÓN LOGÍSTICA\")\n",
    "# Con datos originales\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_orig, val_acc_lr_orig, val_prec_lr_orig, val_rec_lr_orig, val_f1_lr_orig, val_auc_lr_orig = evaluar_modelo(\n",
    "    \"Regresión Logística (original)\", lr, X_train_scaled, y_train, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con SMOTE\n",
    "lr_smote = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_smote, val_acc_lr_smote, val_prec_lr_smote, val_rec_lr_smote, val_f1_lr_smote, val_auc_lr_smote = evaluar_modelo(\n",
    "    \"Regresión Logística (SMOTE)\", lr_smote, X_train_smote, y_train_smote, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con RandomUnderSampler\n",
    "lr_rus = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_rus, val_acc_lr_rus, val_prec_lr_rus, val_rec_lr_rus, val_f1_lr_rus, val_auc_lr_rus = evaluar_modelo(\n",
    "    \"Regresión Logística (RUS)\", lr_rus, X_train_rus, y_train_rus, X_val_scaled, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 11.2 Random Forest\n",
    "print(\"\\n11.2 RANDOM FOREST\")\n",
    "# Con datos originales\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_orig, val_acc_rf_orig, val_prec_rf_orig, val_rec_rf_orig, val_f1_rf_orig, val_auc_rf_orig = evaluar_modelo(\n",
    "    \"Random Forest (original)\", rf, X_train_scaled, y_train, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con SMOTE\n",
    "rf_smote = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_smote, val_acc_rf_smote, val_prec_rf_smote, val_rec_rf_smote, val_f1_rf_smote, val_auc_rf_smote = evaluar_modelo(\n",
    "    \"Random Forest (SMOTE)\", rf_smote, X_train_smote, y_train_smote, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con RandomUnderSampler\n",
    "rf_rus = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_rus, val_acc_rf_rus, val_prec_rf_rus, val_rec_rf_rus, val_f1_rf_rus, val_auc_rf_rus = evaluar_modelo(\n",
    "    \"Random Forest (RUS)\", rf_rus, X_train_rus, y_train_rus, X_val_scaled, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# 11.3 Gradient Boosting\n",
    "print(\"\\n11.3 GRADIENT BOOSTING\")\n",
    "# Con datos originales\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_orig, val_acc_gb_orig, val_prec_gb_orig, val_rec_gb_orig, val_f1_gb_orig, val_auc_gb_orig = evaluar_modelo(\n",
    "    \"Gradient Boosting (original)\", gb, X_train_scaled, y_train, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con SMOTE\n",
    "gb_smote = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_smote, val_acc_gb_smote, val_prec_gb_smote, val_rec_gb_smote, val_f1_gb_smote, val_auc_gb_smote = evaluar_modelo(\n",
    "    \"Gradient Boosting (SMOTE)\", gb_smote, X_train_smote, y_train_smote, X_val_scaled, y_val\n",
    ")\n",
    "\n",
    "# Con RandomUnderSampler\n",
    "gb_rus = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_rus, val_acc_gb_rus, val_prec_gb_rus, val_rec_gb_rus, val_f1_gb_rus, val_auc_gb_rus = evaluar_modelo(\n",
    "    \"Gradient Boosting (RUS)\", gb_rus, X_train_rus, y_train_rus, X_val_scaled, y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Selección del Mejor Modelo y Evaluación en Test\n",
    "\n",
    "Basándonos en los resultados de validación, seleccionamos el mejor modelo y lo evaluamos en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Seleccionar el mejor modelo basado en F1-Score de validación\n",
    "val_modelos = [\n",
    "    (\"LR Original\", lr_orig, X_train_scaled, y_train, val_f1_lr_orig),\n",
    "    (\"LR SMOTE\", lr_smote, X_train_smote, y_train_smote, val_f1_lr_smote),\n",
    "    (\"LR RUS\", lr_rus, X_train_rus, y_train_rus, val_f1_lr_rus),\n",
    "    (\"RF Original\", rf_orig, X_train_scaled, y_train, val_f1_rf_orig),\n",
    "    (\"RF SMOTE\", rf_smote, X_train_smote, y_train_smote, val_f1_rf_smote),\n",
    "    (\"RF RUS\", rf_rus, X_train_rus, y_train_rus, val_f1_rf_rus),\n",
    "    (\"GB Original\", gb_orig, X_train_scaled, y_train, val_f1_gb_orig),\n",
    "    (\"GB SMOTE\", gb_smote, X_train_smote, y_train_smote, val_f1_gb_smote),\n",
    "    (\"GB RUS\", gb_rus, X_train_rus, y_train_rus, val_f1_gb_rus)\n",
    "]\n",
    "\n",
    "mejor_val_modelo_info = max(val_modelos, key=lambda x: x[4])\n",
    "mejor_nombre, mejor_modelo, mejor_X_train, mejor_y_train, mejor_f1_val = mejor_val_modelo_info\n",
    "\n",
    "print(f\"El mejor modelo según la validación es: {mejor_nombre} con F1-Score de {mejor_f1_val:.4f}\")\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "print(\"\\n12. EVALUACIÓN EN CONJUNTO DE PRUEBA\")\n",
    "_, _, _, _, _, _, test_acc, test_prec, test_rec, test_f1 = evaluar_modelo(\n",
    "    f\"{mejor_nombre} (Test Final)\", mejor_modelo, \n",
    "    mejor_X_train, mejor_y_train,\n",
    "    X_val_scaled, y_val,  # para mantener las gráficas de validación\n",
    "    X_test_scaled, y_test  # evaluación en test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Importancia de Características\n",
    "\n",
    "Analizamos la importancia relativa de cada característica en el modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importancia de características\n",
    "if hasattr(mejor_modelo, 'feature_importances_'):\n",
    "    print(\"\\n13. IMPORTANCIA DE CARACTERÍSTICAS\")\n",
    "    importances = mejor_modelo.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.title('Importancia de Características', fontsize=16)\n",
    "    plt.barh(range(len(features)), importances[indices], align='center', color='steelblue')\n",
    "    plt.yticks(range(len(features)), [features[i] for i in indices], fontsize=12)\n",
    "    plt.xlabel('Importancia Relativa', fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nCaracterísticas ordenadas por importancia:\")\n",
    "    for i in range(len(features)):\n",
    "        print(f\"{features[indices[i]]}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicación de la Importancia de Características\n",
    "\n",
    "#### ¿Qué es la Importancia de Características?\n",
    "\n",
    "La importancia de características es una medida que indica cuánto contribuye cada variable predictora al rendimiento del modelo. En modelos basados en árboles como Random Forest y Gradient Boosting, esta importancia se calcula de manera diferente:\n",
    "\n",
    "- **Random Forest**: Utiliza principalmente la **reducción de impureza de Gini** o la **reducción de entropía**. Cada vez que se utiliza una característica para dividir un nodo, se calcula cuánto mejora la pureza de las clases. La suma de estas mejoras a través de todos los árboles se normaliza para obtener la importancia relativa.\n",
    "\n",
    "- **Gradient Boosting**: Utiliza la **reducción en la función de pérdida** que se obtiene al dividir según cada característica.\n",
    "\n",
    "#### Cómo Interpretar la Gráfica\n",
    "\n",
    "1. **Eje Y**: Muestra los nombres de las características, ordenadas de mayor a menor importancia.\n",
    "2. **Eje X**: Representa la importancia relativa de cada característica, expresada como un valor entre 0 y 1, donde la suma de todas las importancias es 1.\n",
    "3. **Barras**: La longitud de cada barra indica la importancia relativa de la característica correspondiente. Las características con barras más largas son más influyentes en las predicciones del modelo.\n",
    "\n",
    "#### Interpretación de los Resultados\n",
    "\n",
    "Normalmente, observamos que:\n",
    "\n",
    "1. **Variables dominantes**: `cfs` (caudal) y `p01m` (precipitación) suelen ser las características más importantes, lo que concuerda con nuestra intuición hidrológica y con los análisis de correlación previos.\n",
    "\n",
    "2. **Variables de rezago**: Las variables de rezago (lag) pueden tener importancia moderada, lo que indica que las condiciones previas influyen en la predicción de inundaciones.\n",
    "\n",
    "3. **Variables temporales cíclicas**: Las variables `sin_hora`, `cos_hora`, `sin_mes`, `cos_mes` generalmente tienen menor importancia, pero aún pueden capturar patrones estacionales o diarios relevantes.\n",
    "\n",
    "#### Implicaciones\n",
    "\n",
    "- **Para el modelo**: Podríamos considerar simplificar el modelo eliminando las características menos importantes, aunque los modelos basados en árboles suelen manejar bien las características irrelevantes.\n",
    "\n",
    "- **Para la comprensión del fenómeno**: Nos ayuda a entender los factores más determinantes en la predicción de inundaciones, lo que puede informar estrategias de monitoreo y alerta temprana.\n",
    "\n",
    "- **Para futuras mejoras**: Podríamos enfocarnos en mejorar la precisión o la frecuencia de medición de las características más importantes, o buscar variables adicionales relacionadas con ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Validación Cruzada del Mejor Modelo\n",
    "\n",
    "Realizamos una validación cruzada para evaluar la robustez del mejor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Validación cruzada con el mejor modelo\n",
    "print(\"\\n14. VALIDACIÓN CRUZADA\")\n",
    "\n",
    "# Realizar validación cruzada con el mejor modelo\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(mejor_modelo, mejor_X_train, mejor_y_train, cv=cv, scoring='f1')\n",
    "print(f\"Resultados de validación cruzada (F1-Score): {cv_scores}\")\n",
    "print(f\"Promedio de F1-Score en validación cruzada: {cv_scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar de F1-Score: {cv_scores.std():.4f}\")\n",
    "\n",
    "# Visualizar los resultados de validación cruzada\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, 6), cv_scores, color='steelblue')\n",
    "plt.axhline(y=cv_scores.mean(), color='red', linestyle='-', label=f'Promedio: {cv_scores.mean():.4f}')\n",
    "plt.xlabel('Fold', fontsize=14)\n",
    "plt.ylabel('F1-Score', fontsize=14)\n",
    "plt.title(f'Resultados de Validación Cruzada para {mejor_nombre}', fontsize=16)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resumen de Resultados de Validación\n",
    "\n",
    "Comparamos los resultados de todos los modelos para identificar el mejor enfoque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Resumen de resultados de validación\n",
    "print(\"\\n15. RESUMEN DE RESULTADOS DE TODOS LOS MODELOS EN VALIDACIÓN\")\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "val_results = pd.DataFrame({\n",
    "    'Modelo': ['LR Original', 'LR SMOTE', 'LR RUS', \n",
    "               'RF Original', 'RF SMOTE', 'RF RUS',\n",
    "               'GB Original', 'GB SMOTE', 'GB RUS'],\n",
    "    'Accuracy': [val_acc_lr_orig, val_acc_lr_smote, val_acc_lr_rus,\n",
    "                val_acc_rf_orig, val_acc_rf_smote, val_acc_rf_rus,\n",
    "                val_acc_gb_orig, val_acc_gb_smote, val_acc_gb_rus],\n",
    "    'Precision': [val_prec_lr_orig, val_prec_lr_smote, val_prec_lr_rus,\n",
    "                 val_prec_rf_orig, val_prec_rf_smote, val_prec_rf_rus,\n",
    "                 val_prec_gb_orig, val_prec_gb_smote, val_prec_gb_rus],\n",
    "    'Recall': [val_rec_lr_orig, val_rec_lr_smote, val_rec_lr_rus,\n",
    "              val_rec_rf_orig, val_rec_rf_smote, val_rec_rf_rus,\n",
    "              val_rec_gb_orig, val_rec_gb_smote, val_rec_gb_rus],\n",
    "    'F1-Score': [val_f1_lr_orig, val_f1_lr_smote, val_f1_lr_rus,\n",
    "                val_f1_rf_orig, val_f1_rf_smote, val_f1_rf_rus,\n",
    "                val_f1_gb_orig, val_f1_gb_smote, val_f1_gb_rus],\n",
    "    'AUC': [val_auc_lr_orig, val_auc_lr_smote, val_auc_lr_rus,\n",
    "           val_auc_rf_orig, val_auc_rf_smote, val_auc_rf_rus,\n",
    "           val_auc_gb_orig, val_auc_gb_smote, val_auc_gb_rus]\n",
    "})\n",
    "\n",
    "# Mostrar la tabla de resultados\n",
    "val_results.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizar comparación de F1-Score entre modelos (validación)\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax = sns.barplot(x='Modelo', y='F1-Score', data=val_results, palette='viridis')\n",
    "plt.title('Comparación de F1-Score entre Modelos (Validación)', fontsize=18)\n",
    "plt.xlabel('Modelo', fontsize=14)\n",
    "plt.ylabel('F1-Score', fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Añadir etiquetas con los valores\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(f'{p.get_height():.4f}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height() + 0.01), \n",
    "                ha = 'center', va = 'bottom', fontsize=12, rotation=0)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusiones\n",
    "\n",
    "### Hallazgos Principales\n",
    "\n",
    "1. **Alta Predictibilidad**: Los eventos de inundación pueden ser predichos con extraordinaria precisión utilizando las variables disponibles, particularmente con modelos de ensamble como Random Forest y Gradient Boosting.\n",
    "\n",
    "2. **Variables Críticas**: El caudal (`cfs`) y la precipitación (`p01m`) son los indicadores más importantes para predecir eventos de inundación, representando aproximadamente el 99% de la importancia total de las características.\n",
    "\n",
    "3. **Efectividad de Modelos Complejos**: Los modelos basados en árboles superaron significativamente a la Regresión Logística, especialmente en el manejo del desbalance de clases.\n",
    "\n",
    "4. **Estrategias de Balanceo**: El uso de técnicas como SMOTE y RandomUnderSampler mostró resultados variables, pero en general SMOTE tendió a producir modelos con mejor rendimiento en términos de F1-Score.\n",
    "\n",
    "5. **Robustez del Modelo**: La validación cruzada y la evaluación en conjuntos separados (train/validation/test) confirman la estabilidad y confiabilidad de nuestro modelo final.\n",
    "\n",
    "### Recomendaciones\n",
    "\n",
    "1. **Implementar un Sistema de Alerta Temprana**: Utilizar el modelo seleccionado para predecir eventos de inundación con anticipación.\n",
    "\n",
    "2. **Incorporar Variables Adicionales**: Considerar la inclusión de otras variables meteorológicas y geográficas para mejorar aún más el modelo.\n",
    "\n",
    "3. **Explorar Modelos Temporales Avanzados**: Evaluar el uso de modelos específicos para series temporales como LSTM o GRU para capturar mejor la dinámica temporal.\n",
    "\n",
    "4. **Monitoreo Continuo**: Establecer un proceso de monitoreo y actualización regular del modelo con nuevos datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
